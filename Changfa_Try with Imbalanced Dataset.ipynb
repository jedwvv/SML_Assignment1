{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a096f214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain 1 label frequencies:\n",
      " label\n",
      "1    2500\n",
      "0    2500\n",
      "Name: count, dtype: int64\n",
      "Domain 2 label frequencies:\n",
      " label\n",
      "0    11500\n",
      "1     1500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "domain1_df = pd.read_json('domain1_train_data.json', lines=True)\n",
    "domain2_df = pd.read_json('domain2_train_data.json', lines=True)\n",
    "\n",
    "# Calculate label frequencies for domain 1\n",
    "label_counts_d1 = domain1_df['label'].value_counts()\n",
    "\n",
    "# Calculate label frequencies for domain 2\n",
    "label_counts_d2 = domain2_df['label'].value_counts()\n",
    "\n",
    "print(\"Domain 1 label frequencies:\\n\", label_counts_d1)\n",
    "print(\"Domain 2 label frequencies:\\n\", label_counts_d2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7adf1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier, IsolationForest, RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "981940e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "def load_data(file_path):\n",
    "    return pd.read_json(file_path, lines=True)\n",
    "\n",
    "df_domain1 = load_data('domain1_train_data.json')\n",
    "df_domain2 = load_data('domain2_train_data.json')\n",
    "df_test = load_data('test_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e364fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine texts from both domains and test data for vectorization\n",
    "all_texts = pd.concat([df_domain1['text'], df_domain2['text'], df_test['text']]).apply(lambda x: ' '.join(map(str, x)))\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_all = vectorizer.fit_transform(all_texts)\n",
    "\n",
    "# Split the vectorized data back into domain1, domain2, and test sets\n",
    "X_domain1 = X_all[:len(df_domain1)]\n",
    "X_domain2 = X_all[len(df_domain1):-len(df_test)]\n",
    "X_test = X_all[-len(df_test):]\n",
    "\n",
    "# Save vectorizer for later use\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc5bbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain Classifier Accuracy: 0.9975\n"
     ]
    }
   ],
   "source": [
    "# Create domain labels (0 for domain1, 1 for domain2)\n",
    "y_domains = [0]*len(df_domain1) + [1]*len(df_domain2)\n",
    "X_domains = vectorizer.transform(pd.concat([df_domain1['text'], df_domain2['text']]).apply(lambda x: ' '.join(map(str, x))))\n",
    "\n",
    "# Train-test split\n",
    "X_train_domain, X_val_domain, y_train_domain, y_val_domain = train_test_split(X_domains, y_domains, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train domain classifier\n",
    "clf1 = LogisticRegression(random_state=42)\n",
    "clf2 = RandomForestClassifier(random_state=42)\n",
    "clf3 = SVC(probability=True, random_state=42)\n",
    "\n",
    "domain_classifier = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2), ('svc', clf3)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "domain_classifier.fit(X_train_domain, y_train_domain)\n",
    "\n",
    "# Save domain classifier\n",
    "joblib.dump(domain_classifier, 'domain_classifier.pkl')\n",
    "\n",
    "y_pred_domain = domain_classifier.predict(X_val_domain)\n",
    "print(\"Domain Classifier Accuracy:\", accuracy_score(y_val_domain, y_pred_domain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d98ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing text data for domain 1\n",
    "df_domain1['text_str'] = df_domain1['text'].apply(lambda tokens: ' '.join(map(str, tokens)))\n",
    "tfidf_vectorizer_d1 = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_domain1 = tfidf_vectorizer_d1.fit_transform(df_domain1['text_str'])\n",
    "\n",
    "# Splitting the data into training and validation sets for domain 1\n",
    "X_train_d1, X_val_d1, y_train_d1, y_val_d1 = train_test_split(X_domain1, df_domain1['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d0c3498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer_d1.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the stacking classifier\n",
    "base_learners = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('svc', SVC(probability=True, random_state=42)),\n",
    "    ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "\n",
    "# Meta-learner\n",
    "meta_learner = LogisticRegression()\n",
    "\n",
    "# Stacking classifier\n",
    "stacking_cls = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
    "\n",
    "# Train the stacking classifier\n",
    "stacking_cls.fit(X_train_d1, y_train_d1)\n",
    "\n",
    "# Prediction on the test set\n",
    "y_pred_d1 = stacking_cls.predict(X_val_d1)\n",
    "\n",
    "# Save classifiers\n",
    "joblib.dump(stacking_cls, 'ai_human_classifier_d1.pkl')\n",
    "joblib.dump(tfidf_vectorizer_d1,'tfidf_vectorizer_d1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c21cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use GridSearchCV or similar tools here to tune hyperparameters\n",
    "param_grid = {\n",
    "    'rf__max_depth': [10, 20, None],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__max_features': ['sqrt', 'log2', None],\n",
    "    'gb__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'gb__subsample': [0.5, 0.75, 1.0],\n",
    "    'svc__C': [0.1, 1, 10],\n",
    "    'svc__gamma': ['scale', 'auto', 0.1],\n",
    "    'final_estimator__C': [0.1, 1, 10],\n",
    "    'final_estimator__solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=stacking_cls, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_d1, y_train_d1)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e2942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation (example for domain 1)\n",
    "print(\"Accuracy (Domain 1):\", accuracy_score(y_val_d1, y_pred_d1))\n",
    "print(\"F1-Score (Domain 1):\", f1_score(y_val_d1, y_pred_d1))\n",
    "print(\"ROC-AUC (Domain 1):\", roc_auc_score(y_val_d1, y_pred_d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2488696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing text data for domain 2\n",
    "df_domain2['text_str'] = df_domain2['text'].apply(lambda tokens: ' '.join(map(str, tokens)))\n",
    "tfidf_vectorizer_d2 = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_domain2 = tfidf_vectorizer_d1.fit_transform(df_domain2['text_str'])\n",
    "\n",
    "# Splitting data into training and validation sets\n",
    "X_train_d2, X_val_d2, y_train_d2, y_val_d2 = train_test_split(X_domain2, df_domain2['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528ba2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting labels for Isolation Forest (Isolation Forest treats anomalies as -1)\n",
    "y_train_d2 = np.where(y_train_d2 == 1, -1, 1)  # Assuming human-generated (label 1) as anomalies\n",
    "\n",
    "# Initialize and fit Isolation Forest\n",
    "iso_forest = IsolationForest(n_estimators=100, random_state=42)\n",
    "iso_forest.fit(X_train_d2, y_train_d2)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_val = iso_forest.predict(X_val_d2)\n",
    "# Inverting predictions: -1 (anomalies) to 1, 1 (normal) to 0\n",
    "y_pred_val_adjusted = np.where(y_pred_val == -1, 1, 0)\n",
    "\n",
    "# Save the classifier and vectorizer for domain 2\n",
    "joblib.dump(iso_forest, 'iso_forest_d2.pkl')\n",
    "joblib.dump(tfidf_vectorizer_d2, 'tfidf_vectorizer_d2.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_val_d2, y_pred_val_adjusted))\n",
    "print(\"Accuracy (Domain 2):\", accuracy_score(y_val_d2, y_pred_val_adjusted))\n",
    "print(\"F1-Score (Domain 2):\", f1_score(y_val_d2, y_pred_val_adjusted))\n",
    "print(\"ROC-AUC (Domain 2):\", roc_auc_score(y_val_d2, y_pred_val_adjusted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5736f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import IsolationForest\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# # Custom scorer for tuning (assuming binary labels with 1 for anomalies)\n",
    "# f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "\n",
    "# # Define parameter grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_samples': [0.25, 0.5, 0.75, 'auto'],\n",
    "#     'contamination': [0.01, 0.05, 0.1],\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "\n",
    "# # Initialize model\n",
    "# iso_forest = IsolationForest(random_state=42)\n",
    "\n",
    "# # Grid search with cross-validation\n",
    "# grid_search = GridSearchCV(iso_forest, param_grid, scoring=f1_scorer, cv=5)\n",
    "\n",
    "# # Assuming X_train is your feature matrix\n",
    "# grid_search.fit(X_train_d2, y_train_d2)\n",
    "\n",
    "# # Best model\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# print(f\"Best parameters: {grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5606421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d2, X_val_d2, y_train_d2, y_val_d2 = train_test_split(X_domain2, df_domain2['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "y_train_d2 = np.where(y_train_d2 == 1, -1, 1)  # Assuming human-generated (label 1) as anomalies\n",
    "\n",
    "iso_forest_optimized = IsolationForest(\n",
    "    bootstrap=False,\n",
    "    contamination=0.01,\n",
    "    max_samples=0.5,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on your training data\n",
    "iso_forest_optimized.fit(X_train_d2, y_train_d2)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_val = iso_forest_optimized.predict(X_val_d2)\n",
    "\n",
    "# Inverting predictions: -1 (anomalies) to 1, 1 (normal) to 0\n",
    "y_pred_val_adjusted = np.where(y_pred_val == -1, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c7d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_val_d2, y_pred_val_adjusted))\n",
    "print(\"Accuracy (Domain 2):\", accuracy_score(y_val_d2, y_pred_val_adjusted))\n",
    "print(\"F1-Score (Domain 2):\", f1_score(y_val_d2, y_pred_val_adjusted))\n",
    "print(\"ROC-AUC (Domain 2):\", roc_auc_score(y_val_d2, y_pred_val_adjusted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee98cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved models\n",
    "domain_classifier = joblib.load('domain_classifier.pkl')\n",
    "ai_human_classifier_d1 = joblib.load('ai_human_classifier_d1.pkl')\n",
    "iso_forest_d2 = joblib.load('iso_forest_d2.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctly load pre-fitted vectorizers\n",
    "tfidf_vectorizer_domain = joblib.load('vectorizer.pkl')  # Adjust file path as necessary\n",
    "\n",
    "# Assuming df_test is your test DataFrame and it includes a column 'text' containing tokenized texts\n",
    "df_test['text_str'] = df_test['text'].apply(lambda tokens: ' '.join(map(str, tokens)))\n",
    "\n",
    "# Correctly use the pre-fitted vectorizers to transform the test data\n",
    "X_test_domain = tfidf_vectorizer_domain.transform(df_test['text_str'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b83122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict domain for test data\n",
    "test_domain_preds = domain_classifier.predict(X_test_domain)\n",
    "\n",
    "# Splitting the test data based on domain predictions\n",
    "df_test['predicted_domain'] = test_domain_preds  # Assign domain predictions to a new column in the test DataFrame\n",
    "df_test_d1 = df_test[df_test['predicted_domain'] == 0]  # Filter rows predicted as Domain 1\n",
    "df_test_d2 = df_test[df_test['predicted_domain'] == 1]  # Filter rows predicted as Domain 2\n",
    "\n",
    "# Assuming df_test is your test DataFrame and it includes a column 'text' containing tokenized texts\n",
    "df_test_d1['text_str'] = df_test_d1['text'].apply(lambda tokens: ' '.join(map(str, tokens)))\n",
    "df_test_d2['text_str'] = df_test_d2['text'].apply(lambda tokens: ' '.join(map(str, tokens)))\n",
    "\n",
    "# Assuming df_test already has a 'text_str' column from previous steps\n",
    "# Transform the test data for AI vs Human classification\n",
    "X_test_d1 = tfidf_vectorizer_domain.transform(df_test_d1['text_str'])\n",
    "X_test_d2 = tfidf_vectorizer_domain.transform(df_test_d2['text_str'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4791825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming ai_human_classifier_d1 and ai_human_classifier_d2 are your classifiers for Domain 1 and Domain 2\n",
    "test_ai_human_preds_d1 = ai_human_classifier_d1.predict(X_test_d1)\n",
    "test_ai_human_preds_d2 = iso_forest_optimized.predict(X_test_d2)\n",
    "test_ai_human_preds_d2_adjusted = np.where(test_ai_human_preds_d2 == -1, 1, 0)\n",
    "\n",
    "# Add prediced labels to CSV\n",
    "df_test_d1['Predicted_Label'] = test_ai_human_preds_d1\n",
    "df_test_d2['Predicted_Label'] = test_ai_human_preds_d2\n",
    "\n",
    "# Combine both predictions\n",
    "df_final_predictions = pd.concat([df_test_d1, df_test_d2]).sort_index()\n",
    "\n",
    "# Select only 'id', 'predicted_domain', and 'Predicted_Label' columns\n",
    "df_final_predictions = df_final_predictions[['id', 'predicted_domain', 'Predicted_Label']]\n",
    "\n",
    "# Step 5: Save to CSV\n",
    "df_final_predictions.to_csv('final_predictions_with_domain.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'final_predictions.csv' is your saved CSV file\n",
    "csv_path = 'final_predictions_with_domain.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Assuming 'Predicted_Label' is the column with your labels\n",
    "domain_counts = df['predicted_domain'].value_counts()\n",
    "label_counts = df['Predicted_Label'].value_counts()\n",
    "\n",
    "print(domain_counts)\n",
    "print(label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5e275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c21965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a90c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe2624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea07c892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70f969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc75bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c37366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def feature_select(texts, method=\"tfidf\", sparse=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Converts a list of texts to a feature matrix using specified vectorization method.\n",
    "    \n",
    "    Args:\n",
    "        texts (list[str]): List of text documents.\n",
    "        method (str, optional): Method for vectorization, \"tfidf\" or \"countvectorize\". Defaults to \"tfidf\".\n",
    "        sparse (bool, optional): Whether to return a sparse matrix or convert it to a dense dataframe. Defaults to False.\n",
    "        **kwargs: Additional keyword arguments for the vectorizer.\n",
    "        \n",
    "    Returns:\n",
    "        X (sparse matrix or DataFrame): Transformed feature matrix.\n",
    "        vectorizer (Vectorizer): Fitted vectorizer object.\n",
    "    \"\"\"\n",
    "    # Choose the vectorization method\n",
    "    if method == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer(**kwargs)\n",
    "    elif method == \"countvectorize\":\n",
    "        vectorizer = CountVectorizer(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported method: {method}\")\n",
    "    \n",
    "    # Fit and transform the texts\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    \n",
    "    if sparse:\n",
    "        return X, vectorizer\n",
    "    else:\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        df = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "        return df, vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d562e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9337aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the datasets and prepare the text data for vectorization by converting lists of tokens to strings\n",
    "texts_combined = pd.concat([df_domain1['text'], df_domain2['text']]).apply(lambda x: ' '.join(x)).tolist()\n",
    "\n",
    "# Now, use the feature_select function to vectorize the combined texts\n",
    "X_combined, vectorizer_combined = feature_select(texts_combined, method=\"tfidf\", sparse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5181941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "domain_classifier = LogisticRegression(max_iter=1000)\n",
    "domain_classifier.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Evaluate the classifier\n",
    "domain_accuracy = domain_classifier.score(X_test_combined, y_test_combined)\n",
    "print(f\"Domain classification accuracy: {domain_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec481b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified example for Domain 1 using SVM for AI vs. human classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Prepare data for Domain 1 (you need to split your data into training and test sets)\n",
    "# X_train_domain1, X_test_domain1, y_train_domain1, y_test_domain1 = train_test_split(...)\n",
    "\n",
    "svm_domain1 = SVC(probability=True)\n",
    "svm_domain1.fit(X_train_domain1, y_train_domain1)\n",
    "\n",
    "# For Domain 2, you might use a One-Class SVM or other anomaly detection methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step involves transforming your test data using the same feature extraction\n",
    "# process used for training data, predicting the domain, and then applying the\n",
    "# appropriate domain-specific model for final classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7322bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaacf446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a5339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869385c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split combined domain dataset\n",
    "X_train_domain, X_test_domain, y_train_domain, y_test_domain = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier for domain classification\n",
    "domain_classifier = RandomForestClassifier()\n",
    "domain_classifier.fit(X_train_domain, y_train_domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7793059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Assuming X_domain1, y_domain1 are features and labels for domain 1\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_domain1, y_domain1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Assuming X_domain2 are features for domain 2\n",
    "# Note: Isolation Forest doesn't need labels for fitting\n",
    "iso_forest = IsolationForest()\n",
    "iso_forest.fit(X_domain2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_test are features of the test set\n",
    "test_domain_predictions = domain_classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each test sample, check predicted domain and classify accordingly\n",
    "ai_human_predictions = []\n",
    "for i, domain in enumerate(test_domain_predictions):\n",
    "    if domain == 1:  # Domain 1\n",
    "        pred = svm_classifier.predict([X_test[i]])\n",
    "    else:  # Domain 2 (using anomaly detection scores to determine class)\n",
    "        score = iso_forest.decision_function([X_test[i]])\n",
    "        pred = [1 if s < 0 else 0 for s in score]  # Assuming negative scores are anomalies (human)\n",
    "    ai_human_predictions.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea7c6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb7328e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035951d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a3b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
