{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a096f214",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain 1 label frequencies:\n",
      " 1    2500\n",
      "0    2500\n",
      "Name: label, dtype: int64\n",
      "Domain 2 label frequencies:\n",
      " 0    11500\n",
      "1     1500\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "domain1_df = pd.read_json('domain1_train_data.json', lines=True)\n",
    "domain2_df = pd.read_json('domain2_train_data.json', lines=True)\n",
    "\n",
    "# Calculate label frequencies for domain 1\n",
    "label_counts_d1 = domain1_df['label'].value_counts()\n",
    "\n",
    "# Calculate label frequencies for domain 2\n",
    "label_counts_d2 = domain2_df['label'].value_counts()\n",
    "\n",
    "print(\"Domain 1 label frequencies:\\n\", label_counts_d1)\n",
    "print(\"Domain 2 label frequencies:\\n\", label_counts_d2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7adf1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import GradientBoostingClassifier, IsolationForest, RandomForestClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestNeighbors\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "981940e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "def load_data(file_path):\n",
    "    return pd.read_json(file_path, lines=True)\n",
    "\n",
    "df_domain1 = load_data('domain1_train_data.json')\n",
    "df_domain2 = load_data('domain2_train_data.json')\n",
    "df_test = load_data('test_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e364fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine texts from both domains and test data for vectorization\n",
    "all_texts = pd.concat([df_domain1['text'], df_domain2['text'], df_test['text']]).apply(lambda x: ' '.join(map(str, x)))\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_all = vectorizer.fit_transform(all_texts)\n",
    "\n",
    "# Split the vectorized data back into domain1, domain2, and test sets\n",
    "X_domain1 = X_all[:len(df_domain1)]\n",
    "X_domain2 = X_all[len(df_domain1):-len(df_test)]\n",
    "X_test = X_all[-len(df_test):]\n",
    "\n",
    "# Save vectorizer for later use\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc5bbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain Classifier Accuracy: 0.9975\n"
     ]
    }
   ],
   "source": [
    "# Create domain labels (0 for domain1, 1 for domain2)\n",
    "y_domains = [0]*len(df_domain1) + [1]*len(df_domain2)\n",
    "X_domains = vectorizer.transform(pd.concat([df_domain1['text'], df_domain2['text']]).apply(lambda x: ' '.join(map(str, x))))\n",
    "\n",
    "# Train-test split\n",
    "X_train_domain, X_val_domain, y_train_domain, y_val_domain = train_test_split(X_domains, y_domains, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train domain classifier\n",
    "clf1 = LogisticRegression(random_state=42)\n",
    "clf2 = RandomForestClassifier(random_state=42)\n",
    "clf3 = SVC(probability=True, random_state=42)\n",
    "\n",
    "domain_classifier = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2), ('svc', clf3)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "domain_classifier.fit(X_train_domain, y_train_domain)\n",
    "\n",
    "# Save domain classifier\n",
    "joblib.dump(domain_classifier, 'domain_classifier.pkl')\n",
    "\n",
    "y_pred_domain = domain_classifier.predict(X_val_domain)\n",
    "print(\"Domain Classifier Accuracy:\", accuracy_score(y_val_domain, y_pred_domain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d98ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing text data for domain 1\n",
    "df_domain1['text_str'] = df_domain1['text'].apply(lambda tokens: ' '.join(map(str, tokens)))\n",
    "tfidf_vectorizer_d1 = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_domain1 = tfidf_vectorizer_d1.fit_transform(df_domain1['text_str'])\n",
    "\n",
    "# Splitting the data into training and validation sets for domain 1\n",
    "X_train_d1, X_val_d1, y_train_d1, y_val_d1 = train_test_split(X_domain1, df_domain1['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0c3498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer_d1.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the stacking classifier\n",
    "base_learners = [\n",
    "    ('dt', DecisionTreeClassifier(random_state=42)), \n",
    "    ('svc', SVC(probability=True, random_state=42)), \n",
    "    ('lr', LogisticRegression(random_state=42)), \n",
    "    ('knn', KNeighborsClassifier())\n",
    "]\n",
    "\n",
    "# Meta-learner\n",
    "meta_learner = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Stacking classifier\n",
    "stacking_cls_d1 = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
    "\n",
    "# Train the stacking classifier\n",
    "stacking_cls_d1.fit(X_train_d1, y_train_d1)\n",
    "\n",
    "# Prediction on the test set\n",
    "y_pred_d1 = stacking_cls_d1.predict(X_val_d1)\n",
    "\n",
    "# Save classifiers\n",
    "joblib.dump(stacking_cls_d1, 'ai_human_classifier_d1.pkl')\n",
    "joblib.dump(tfidf_vectorizer_d1,'tfidf_vectorizer_d1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58689bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Domain 1): 0.828\n",
      "F1-Score (Domain 1): 0.8323586744639376\n",
      "ROC-AUC (Domain 1): 0.8280000000000001\n"
     ]
    }
   ],
   "source": [
    "# Evaluation (example for domain 1)\n",
    "print(\"Accuracy (Domain 1):\", accuracy_score(y_val_d1, y_pred_d1))\n",
    "print(\"F1-Score (Domain 1):\", f1_score(y_val_d1, y_pred_d1))\n",
    "print(\"ROC-AUC (Domain 1):\", roc_auc_score(y_val_d1, y_pred_d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2488696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing text data for domain 2\n",
    "df_domain2['text_str'] = df_domain2['text'].apply(lambda tokens: ' '.join(map(str, tokens)))\n",
    "tfidf_vectorizer_d2 = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_domain2 = tfidf_vectorizer_d2.fit_transform(df_domain2['text_str'])\n",
    "y_domain2 = df_domain2['label']\n",
    "\n",
    "# Splitting data into training and validation sets\n",
    "X_train_d2, X_val_d2, y_train_d2, y_val_d2 = train_test_split(X_domain2, y_domain2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d34622ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer_d2.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_d2, y_train_d2)\n",
    "\n",
    "# Initialize a classifier, for example, RandomForest\n",
    "stacking_cls_d2 = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
    "\n",
    "# Train the classifier on the oversampled training data\n",
    "stacking_cls_d2.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_d2 = stacking_cls_d2.predict(X_val_d2)\n",
    "\n",
    "# Save classifiers\n",
    "joblib.dump(stacking_cls_d2, 'ai_human_classifier_d2.pkl')\n",
    "joblib.dump(tfidf_vectorizer_d2,'tfidf_vectorizer_d2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a329db54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9084615384615384\n",
      "Accuracy (Domain 2): 0.9084615384615384\n",
      "F1-Score (Domain 2): 0.4079601990049751\n",
      "ROC-AUC (Domain 2): 0.6298668734433801\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_val_d2, y_pred_d2))\n",
    "print(\"Accuracy (Domain 2):\", accuracy_score(y_val_d2, y_pred_d2))\n",
    "print(\"F1-Score (Domain 2):\", f1_score(y_val_d2, y_pred_d2))\n",
    "print(\"ROC-AUC (Domain 2):\", roc_auc_score(y_val_d2, y_pred_d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee98cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved models\n",
    "domain_classifier = joblib.load('domain_classifier.pkl')\n",
    "ai_human_classifier_d1 = joblib.load('ai_human_classifier_d1.pkl')\n",
    "ai_human_classifier_d2 = joblib.load('ai_human_classifier_d2.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd0c8c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correctly load pre-fitted vectorizers\n",
    "tfidf_vectorizer_domain = joblib.load('vectorizer.pkl')  # Adjust file path as necessary\n",
    "\n",
    "# Assuming df_test is your test DataFrame and it includes a column 'text' containing tokenized texts\n",
    "df_test['text_str'] = df_test['text'].apply(lambda tokens: ' '.join(map(str, tokens)))\n",
    "\n",
    "# Correctly use the pre-fitted vectorizers to transform the test data\n",
    "X_test_domain = tfidf_vectorizer_domain.transform(df_test['text_str'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4b83122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/tvj0_bqn32v820xmvm68s3880000gp/T/ipykernel_49775/3257377892.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_d1['text_str'] = df_test_d1['text'].apply(lambda tokens: ' '.join(map(str, tokens)))\n",
      "/var/folders/wj/tvj0_bqn32v820xmvm68s3880000gp/T/ipykernel_49775/3257377892.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_d2['text_str'] = df_test_d2['text'].apply(lambda tokens: ' '.join(map(str, tokens)))\n"
     ]
    }
   ],
   "source": [
    "# Predict domain for test data\n",
    "test_domain_preds = domain_classifier.predict(X_test_domain)\n",
    "\n",
    "# Splitting the test data based on domain predictions\n",
    "df_test['predicted_domain'] = test_domain_preds  # Assign domain predictions to a new column in the test DataFrame\n",
    "df_test_d1 = df_test[df_test['predicted_domain'] == 0]  # Filter rows predicted as Domain 1\n",
    "df_test_d2 = df_test[df_test['predicted_domain'] == 1]  # Filter rows predicted as Domain 2\n",
    "\n",
    "# Assuming df_test is your test DataFrame and it includes a column 'text' containing tokenized texts\n",
    "df_test_d1['text_str'] = df_test_d1['text'].apply(lambda tokens: ' '.join(map(str, tokens)))\n",
    "df_test_d2['text_str'] = df_test_d2['text'].apply(lambda tokens: ' '.join(map(str, tokens)))\n",
    "\n",
    "# Assuming df_test already has a 'text_str' column from previous steps\n",
    "# Transform the test data for AI vs Human classification\n",
    "X_test_d1 = tfidf_vectorizer_domain.transform(df_test_d1['text_str'])\n",
    "X_test_d2 = tfidf_vectorizer_domain.transform(df_test_d2['text_str'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4791825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wj/tvj0_bqn32v820xmvm68s3880000gp/T/ipykernel_49775/1585613002.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_d1['Predicted_Label'] = test_ai_human_preds_d1\n",
      "/var/folders/wj/tvj0_bqn32v820xmvm68s3880000gp/T/ipykernel_49775/1585613002.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_d2['Predicted_Label'] = test_ai_human_preds_d2\n"
     ]
    }
   ],
   "source": [
    "# Classify between AI and Human \n",
    "test_ai_human_preds_d1 = ai_human_classifier_d1.predict(X_test_d1)\n",
    "test_ai_human_preds_d2 = ai_human_classifier_d2.predict(X_test_d2)\n",
    "\n",
    "# Add prediced labels to CSV\n",
    "df_test_d1['Predicted_Label'] = test_ai_human_preds_d1\n",
    "df_test_d2['Predicted_Label'] = test_ai_human_preds_d2\n",
    "\n",
    "# Combine both predictions\n",
    "df_final_predictions = pd.concat([df_test_d1, df_test_d2]).sort_index()\n",
    "\n",
    "# Select only 'id', 'predicted_domain', and 'Predicted_Label' columns\n",
    "df_final_predictions = df_final_predictions[['id', 'predicted_domain', 'Predicted_Label']]\n",
    "\n",
    "# Save to CSV\n",
    "df_final_predictions.to_csv('final_predictions_with_domain.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06ab443e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2007\n",
      "0    1993\n",
      "Name: predicted_domain, dtype: int64\n",
      "0    2512\n",
      "1    1488\n",
      "Name: Predicted_Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'final_predictions.csv' is your saved CSV file\n",
    "csv_path = 'final_predictions_with_domain.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Assuming 'Predicted_Label' is the column with your labels\n",
    "domain_counts = df['predicted_domain'].value_counts()\n",
    "label_counts = df['Predicted_Label'].value_counts()\n",
    "\n",
    "print(domain_counts)\n",
    "print(label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5e275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c21965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a90c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfe2624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea07c892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef70f969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dc75bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c37366b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def feature_select(texts, method=\"tfidf\", sparse=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Converts a list of texts to a feature matrix using specified vectorization method.\n",
    "    \n",
    "    Args:\n",
    "        texts (list[str]): List of text documents.\n",
    "        method (str, optional): Method for vectorization, \"tfidf\" or \"countvectorize\". Defaults to \"tfidf\".\n",
    "        sparse (bool, optional): Whether to return a sparse matrix or convert it to a dense dataframe. Defaults to False.\n",
    "        **kwargs: Additional keyword arguments for the vectorizer.\n",
    "        \n",
    "    Returns:\n",
    "        X (sparse matrix or DataFrame): Transformed feature matrix.\n",
    "        vectorizer (Vectorizer): Fitted vectorizer object.\n",
    "    \"\"\"\n",
    "    # Choose the vectorization method\n",
    "    if method == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer(**kwargs)\n",
    "    elif method == \"countvectorize\":\n",
    "        vectorizer = CountVectorizer(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported method: {method}\")\n",
    "    \n",
    "    # Fit and transform the texts\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    \n",
    "    if sparse:\n",
    "        return X, vectorizer\n",
    "    else:\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        df = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "        return df, vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d562e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9337aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the datasets and prepare the text data for vectorization by converting lists of tokens to strings\n",
    "texts_combined = pd.concat([df_domain1['text'], df_domain2['text']]).apply(lambda x: ' '.join(x)).tolist()\n",
    "\n",
    "# Now, use the feature_select function to vectorize the combined texts\n",
    "X_combined, vectorizer_combined = feature_select(texts_combined, method=\"tfidf\", sparse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5181941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "domain_classifier = LogisticRegression(max_iter=1000)\n",
    "domain_classifier.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# Evaluate the classifier\n",
    "domain_accuracy = domain_classifier.score(X_test_combined, y_test_combined)\n",
    "print(f\"Domain classification accuracy: {domain_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec481b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified example for Domain 1 using SVM for AI vs. human classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Prepare data for Domain 1 (you need to split your data into training and test sets)\n",
    "# X_train_domain1, X_test_domain1, y_train_domain1, y_test_domain1 = train_test_split(...)\n",
    "\n",
    "svm_domain1 = SVC(probability=True)\n",
    "svm_domain1.fit(X_train_domain1, y_train_domain1)\n",
    "\n",
    "# For Domain 2, you might use a One-Class SVM or other anomaly detection methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fa398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This step involves transforming your test data using the same feature extraction\n",
    "# process used for training data, predicting the domain, and then applying the\n",
    "# appropriate domain-specific model for final classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7322bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaacf446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a5339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869385c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split combined domain dataset\n",
    "X_train_domain, X_test_domain, y_train_domain, y_test_domain = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier for domain classification\n",
    "domain_classifier = RandomForestClassifier()\n",
    "domain_classifier.fit(X_train_domain, y_train_domain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7793059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Assuming X_domain1, y_domain1 are features and labels for domain 1\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_domain1, y_domain1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Assuming X_domain2 are features for domain 2\n",
    "# Note: Isolation Forest doesn't need labels for fitting\n",
    "iso_forest = IsolationForest()\n",
    "iso_forest.fit(X_domain2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_test are features of the test set\n",
    "test_domain_predictions = domain_classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each test sample, check predicted domain and classify accordingly\n",
    "ai_human_predictions = []\n",
    "for i, domain in enumerate(test_domain_predictions):\n",
    "    if domain == 1:  # Domain 1\n",
    "        pred = svm_classifier.predict([X_test[i]])\n",
    "    else:  # Domain 2 (using anomaly detection scores to determine class)\n",
    "        score = iso_forest.decision_function([X_test[i]])\n",
    "        pred = [1 if s < 0 else 0 for s in score]  # Assuming negative scores are anomalies (human)\n",
    "    ai_human_predictions.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea7c6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb7328e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035951d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a3b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
