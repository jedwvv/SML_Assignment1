{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filepath):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        dataset = [ json.loads(line, parse_int = str) for line in f ]\n",
    "    return dataset\n",
    "\n",
    "def get_vectorizer( texts: list[str], *, method=\"countvectorize\", **kwargs ) -> CountVectorizer:\n",
    "    \"\"\"From a list of texts, output an appropriate vectorizer either using CountVectorizer or TF-IDF depending on method argument. \n",
    "\n",
    "     Args:\n",
    "         texts (list[str]): list of strings, each item corresponding to a text.\n",
    "         method (str, optional): Method to select features. Defaults to \"count-vectorizer\".\n",
    "         **kwargs: kwarg arguments to pass to Vectorizer classes of sklearn.\n",
    "    Raises:\n",
    "        ValueError: If passing an non-specified method of text feature extraction\n",
    "\n",
    "     Returns:\n",
    "         pd.DataFrame: dataframe of shape (n_samples, n_features)\n",
    "    \"\"\"\n",
    "    #We want single digits to be tokenized. This regex considers everything as a token except whitespace.\n",
    "    kwargs['token_pattern'] = r'\\S+' \n",
    "    if method == \"countvectorize\":\n",
    "        vectorizer = CountVectorizer(**kwargs)\n",
    "    elif method == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"{method} is not a supported method.\")\n",
    "    #Use texts to initialize vocabulary of vectorizer\n",
    "    vectorizer.fit(texts)\n",
    "    return vectorizer\n",
    "\n",
    "def sentencify(text: list) -> str:\n",
    "    sentence = \" \".join(text) \n",
    "    return sentence\n",
    "\n",
    "def loss(clf, X, y):\n",
    "    probs = clf.predict_log_proba(X)\n",
    "    y0 = probs[:,1]\n",
    "    y1 = probs[:,0]\n",
    "    loss = -y*y0 - (1-y)*y1\n",
    "    loss = loss.sum()/y.size\n",
    "    return loss\n",
    "\n",
    "def balanced_acc(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    return balanced_accuracy_score(y, y_pred, adjusted=False)\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = load_dataset(\"domain2_train_data.json\")\n",
    "datatexts_2 = [ sentencify(instance['text']) for instance in dataset_2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no features: 91931\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = get_vectorizer( texts = datatexts_2,\n",
    "                                    method='tfidf',\n",
    "                                    use_idf=True,\n",
    "                                    ngram_range=(1,3),\n",
    "                                    max_df=0.995, #Ignore vocabulary appearing too frequently, probably words like \"is\", \"are\", \"and\", \"this\" etc.\n",
    "                                    min_df=10, #Ignore vocabulary that is too infrequent, as this may lead to low prediction accuracy.\n",
    "                                    )\n",
    "print(f\"no features: {tfidf_vectorizer.get_feature_names_out().size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = tfidf_vectorizer.transform( datatexts_2 ).toarray()\n",
    "y = np.array([1]*1500 + [0]*11500)\n",
    "lengths = np.zeros( (13000, 2) )\n",
    "for i in range(13000):\n",
    "    for k in range(2):\n",
    "        lengths[i,k] = len(dataset_2[i]['text'])**(k+1)\n",
    "lengths[:,0] /= lengths.max(axis=0)[0]\n",
    "lengths[:,1] /= lengths.max(axis=0)[1]\n",
    "X2 = np.hstack( (X2, lengths) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27241"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_clf = LogisticRegression(C=0.1, random_state=0)\n",
    "selector_clf.fit(X2, y)\n",
    "selector = SelectFromModel(selector_clf, prefit=True)\n",
    "selector.fit(X2, y)\n",
    "selector.get_feature_names_out().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline( [(\"selector\", selector),\n",
    "                      (\"clf\", LogisticRegression(C=1, tol=1e-4, random_state=1, class_weight=\"balanced\"))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9134782608695653\n",
      "0.912463768115942\n",
      "0.9148550724637681\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "for train_idces, test_idces in cv.split(X2, y):\n",
    "    X_train, y_train = X2[train_idces,:], y[train_idces]\n",
    "    X_test, y_test = X2[test_idces,:], y[test_idces]\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    mnb = balanced_acc( pipeline, X_test, y_test )\n",
    "    print(mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"domain2_lr.mdl\", \"wb\") as f:\n",
    "    pkl.dump( [tfidf_vectorizer, pipeline], f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
