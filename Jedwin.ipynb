{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Description](https://www.kaggle.com/competitions/comp90051-2024s1-project-1)\n",
    "Text generation has become an increasingly popular task with the rise of natural language processing (NLP) techniques and advancements in deep learning. Given a short text prompt written by a human, text generation employs overparameterised models to generate response text: a likely sequence of text that might follow the prompt, based on enormous training datasets of text from news articles, online libraries of books, and from scraping the web. While text generation has a wide range of applications, including chatbots, language translation, and content creation, it also poses a significant challenge in ensuring content authenticity, accuracy, and authoritativeness. This is where text generation detection comes in, which is the process of identifying whether a given text is machine-generated or human-written. Developing effective text generation detection models is important because it can help prevent the spread of fake news, misinformation, and propaganda.\n",
    "\n",
    "Your task is to come up with test predictions for a machine-generated detection problem given a training set and test input instances. That is, your task is to predict whether given text input instances have been generated by a human or a machine.\n",
    "\n",
    "Full details for this task are provided in the assignment description on Canvas.\n",
    "\n",
    "\n",
    "## [Evaluation](www.kaggle.com/competitions/comp90051-2024s1-project-1/overview/evaluation)\n",
    "For all participants, the same 50% of predictions from the test set are assigned to the public leaderboard. The score you see on the public leaderboard reflects your model’s accuracy on this portion of the test set. The other 50% of the test set will only be used once, after the competition has closed, to determine your final ranking and accuracy scores. This means that you must take care not to overfit to the leaderboard.\n",
    "\n",
    "Submissions will be evaluated using the classification accuracy between the predicted class and the observed target.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import json\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets\n",
    "with open(\"domain1_train_data.json\", \"r\") as f:\n",
    "    dataset_1 = [ json.loads(line, parse_int = str) for line in f ]\n",
    "\n",
    "with open(\"domain2_train_data.json\", \"r\") as f:\n",
    "    dataset_2 = [ json.loads(line, parse_int = str) for line in f ]\n",
    "\n",
    "with open(\"test_data.json\", \"r\") as f:\n",
    "    testset = [ json.loads(line, parse_int = str) for line in f ]\n",
    "\n",
    "n_samples_1 = len(dataset_1)\n",
    "n_samples_2 = len(dataset_2)\n",
    "n_tests = len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a dict of vocabulary containing 1-grams (single words), and n-grams (word sequences)\n",
    "#A key is a unique vocabulary, and the value is its frequency throughout dataset\n",
    "vocab = {}\n",
    "for m in range(n_samples_1):\n",
    "    text = dataset_1[m]['text']\n",
    "    textlength = len(text)\n",
    "    for i in range(textlength):\n",
    "        onegram = f\"{text[i]}\"\n",
    "        vocab[onegram] = vocab.get(onegram, 0) + 1\n",
    "        if i < textlength-1: \n",
    "            twogram = f\"{text[i]} {text[i+1]}\"\n",
    "            vocab[twogram] = vocab.get(twogram, 0) + 1\n",
    "        # if i < textlength-2:\n",
    "        #     threegram = f\"{text[i]} {text[i+1]} {text[i+2]}\"\n",
    "        #     vocab[threegram] = vocab.get(threegram, 0) + 1\n",
    "        \n",
    "\n",
    "for m in range(n_samples_2):\n",
    "    text = dataset_2[m]['text']\n",
    "    textlength = len(text)\n",
    "    for i in range(textlength):\n",
    "        onegram = f\"{text[i]}\"\n",
    "        vocab[onegram] = vocab.get(onegram, 0) + 1\n",
    "        if i < textlength-1: \n",
    "            twogram = f\"{text[i]} {text[i+1]}\"\n",
    "            vocab[twogram] = vocab.get(twogram, 0) + 1\n",
    "        # if i < textlength-2:\n",
    "        #     threegram = f\"{text[i]} {text[i+1]} {text[i+2]}\"\n",
    "        #     vocab[threegram] = vocab.get(threegram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same as above, but we only count how often a vocabulary appears in a document (so repeating \n",
    "vocab = {}\n",
    "for m in range(n_samples_1):\n",
    "    text = dataset_1[m]['text']\n",
    "    textlength = len(text)\n",
    "    for i in range(textlength):\n",
    "        onegram = f\"{text[i]}\"\n",
    "        vocab[onegram] = vocab.get(onegram, 0) + 1\n",
    "        if i < textlength-1: \n",
    "            twogram = f\"{text[i]} {text[i+1]}\"\n",
    "            vocab[twogram] = vocab.get(twogram, 0) + 1\n",
    "        # if i < textlength-2:\n",
    "        #     threegram = f\"{text[i]} {text[i+1]} {text[i+2]}\"\n",
    "        #     vocab[threegram] = vocab.get(threegram, 0) + 1\n",
    "        \n",
    "\n",
    "for m in range(n_samples_2):\n",
    "    text = dataset_2[m]['text']\n",
    "    textlength = len(text)\n",
    "    for i in range(textlength):\n",
    "        onegram = f\"{text[i]}\"\n",
    "        vocab[onegram] = vocab.get(onegram, 0) + 1\n",
    "        if i < textlength-1: \n",
    "            twogram = f\"{text[i]} {text[i+1]}\"\n",
    "            vocab[twogram] = vocab.get(twogram, 0) + 1\n",
    "        # if i < textlength-2:\n",
    "        #     threegram = f\"{text[i]} {text[i+1]} {text[i+2]}\"\n",
    "        #     vocab[threegram] = vocab.get(threegram, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary:  1040230\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of vocabulary: \", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To reduce number of features, just choose ALL 1-grams (like bag of words)\n",
    "#Then include the top most occuring (2,3)-grams\n",
    "# final_vocab = {str(i): i for i in range(83583)} #1-grams\n",
    "# s = 0\n",
    "final_vocab = {}\n",
    "t = 0\n",
    "number_1gram = 0\n",
    "number_2gram = 0\n",
    "\n",
    "#Remove unique words and n-grams in the final vocabulary, as they will act as noise in classifying.\n",
    "for word, count in vocab.items():\n",
    "    if (count > 1) and (\" \" not in word): #1-grams don't have space\n",
    "        final_vocab[ word ] = t\n",
    "        number_1gram += 1\n",
    "        t += 1\n",
    "        \n",
    "    elif (count > 1) and (\" \" in word):\n",
    "        final_vocab[ word ] = t\n",
    "        number_2gram += 1\n",
    "        t += 1\n",
    "\n",
    "# sorted_vocabs = sorted( vocab.items(), key=lambda x:x[1] )\n",
    "# number_ngrams_included = 10000\n",
    "# while s < number_ngrams_included:\n",
    "#     word, count = sorted_vocabs.pop()\n",
    "#     if word not in final_vocab:\n",
    "#         final_vocab[str(word)] = 83583+s\n",
    "#         s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_vocab.json\", \"w\") as f:\n",
    "    json.dump(final_vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def feature_select( texts: list[str], *, vocabulary: dict = None, method=\"countvectorize\", sparse=False, **kwargs ):\n",
    "    \"\"\"From a list of texts, output a dataframe of features with shape (n_samples, n_features).\n",
    "\n",
    "     Args:\n",
    "         texts (list[str]): list of strings, each item corresponding to a text.\n",
    "         vocabulary (dict, optional): _description_. Defaults to None.\n",
    "         method (str, optional): Method to select features. Defaults to \"count-vectorizer\".\n",
    "         **kwargs: kwarg arguments to pass to Vectorizer classes of sklearn.\n",
    "    Raises:\n",
    "        ValueError: If passing an non-specified method of text feature extraction\n",
    "\n",
    "     Returns:\n",
    "         pd.DataFrame: dataframe of shape (n_samples, n_features)\n",
    "    \"\"\"\n",
    "    #We want single digits to tokenized. This regex considers everything as a token except whitespace.\n",
    "    kwargs['token_pattern'] = r'\\S+' \n",
    "    if method == \"countvectorize\":\n",
    "        vectorizer = CountVectorizer(vocabulary = vocabulary, **kwargs) if vocabulary else CountVectorizer(**kwargs)\n",
    "    elif method == \"tfidf\":\n",
    "        vectorizer = TfidfVectorizer(vocabulary = vocabulary, **kwargs) if vocabulary else TfidfVectorizer(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"{method} is not a supported method.\")\n",
    "    if not sparse:\n",
    "        X = vectorizer.fit_transform(texts)\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        df = pd.DataFrame.sparse.from_spmatrix(data=X, columns = feature_names)\n",
    "        return df, vectorizer\n",
    "    else:\n",
    "        X = vectorizer.fit_transform(texts)\n",
    "        return X, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn lists of words from dataset into sentences:\n",
    "datatexts = []\n",
    "for dataset in [dataset_1, dataset_2]:\n",
    "    for instance in dataset:\n",
    "        datatexts += [ \" \".join(instance[\"text\"]) ]\n",
    "testtexts = []\n",
    "for instance in testset:\n",
    "    testtexts += [ \" \".join(instance[\"text\"]) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 65578)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Selection:\n",
    "with open(\"final_vocab.json\", \"r\") as f:\n",
    "    final_vocab = json.load(f)\n",
    "    \n",
    "X, vectorizer = feature_select(texts = datatexts, \n",
    "                    method='tfidf',\n",
    "                    ngram_range=(1,2),\n",
    "                    sparse=True,\n",
    "                    max_df=0.95, #Ignore vocabulary appearing most instances. We expect these are words corresponding to things like \"is\", \"are\", \"and\", \"this\" etc.\n",
    "                    min_df=10, #Ignore vocabulary that is too infrequent, as this may lead to low prediction accuracy.\n",
    "                    )\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labels\n",
    "y = [ [dataset_1[i]['label']] for i in range(n_samples_1) ] \n",
    "y += [ [dataset_2[i]['label']] for i in range(n_samples_2) ]\n",
    "y = pd.DataFrame( y, columns=[\"label\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA, PCA, SparsePCA\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif, SelectKBest\n",
    "\n",
    "# #sparse matrix feature selection\n",
    "# #Feature Selection:\n",
    "# X_sparse, vectorizer = feature_select(texts = datatexts, \n",
    "#                     vocabulary=final_vocab, \n",
    "#                     method='tfidf',\n",
    "#                     ngram_range=(1,2),\n",
    "#                     sparse=True\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Repeat for full vocab\n",
    "# X_sparse_2, vectorizer_2 = feature_select(texts = datatexts, \n",
    "#                     vocabulary=vocab.keys(), \n",
    "#                     method='tfidf',\n",
    "#                     ngram_range=(1,2),\n",
    "#                     sparse=True\n",
    "#                     )\n",
    "# X_sparse_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture pca_transform\n",
    "%%time\n",
    "transformer = IncrementalPCA(n_components=4500, batch_size=4500)\n",
    "X_pca = transformer.fit_transform(X.toarray())\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18000, 4500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.toarray(), y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    train_size=0.8, \n",
    "                                                    random_state=2024, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = MinMaxScaler().fit_transform(X_train.to_numpy(dtype=np.float64))\n",
    "# X_test = MinMaxScaler().fit_transform(X_test.to_numpy(dtype=np.float64))\n",
    "\n",
    "X_train = MinMaxScaler().fit_transform(X_train)\n",
    "X_test = MinMaxScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jvillanueva/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7686111111111111"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "testtexts = [ testset[i]['text'] for i in range(n_tests) ]\n",
    "testtexts = [ \" \".join(testtexts[i]) for i in range(n_tests) ]\n",
    "X_test_featureset = vectorizer.transform( testtexts )\n",
    "# X_test_featureset = transformer.transform( X_test_featureset )\n",
    "X_test_featureset = MinMaxScaler().fit_transform(X_test_featureset.toarray())\n",
    "predictions = classifier.predict( X_test_featureset )\n",
    "predictions = pd.DataFrame( predictions, index=range(n_tests), columns=[ \"class\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "0        2004\n",
       "1        1996\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv(\"sample.csv\", sep=\",\", header=True, index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jvillanueva/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 26.3k/26.3k [00:02<00:00, 10.9kB/s]\n",
      "Successfully submitted to COMP90051 2024S1 Project 1"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c comp90051-2024s1-project-1 -f sample.csv -m \"Using ~4k features only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(1231)\n",
    "random_predicts = pd.DataFrame( [ rng.choice([0,1]) for _ in range(4000) ], index=range(n_tests), columns=[ \"class\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jvillanueva/.kaggle/kaggle.json'\n",
      "100%|██████████████████████████████████████| 26.3k/26.3k [00:01<00:00, 13.6kB/s]\n",
      "Successfully submitted to COMP90051 2024S1 Project 1"
     ]
    }
   ],
   "source": [
    "random_predicts.to_csv(\"random.csv\", sep=\",\", header=True, index_label=\"id\")\n",
    "!kaggle competitions submit -c comp90051-2024s1-project-1 -f random.csv -m \"Completely random guessing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
